<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nlp on Kangwei Ling</title>
    <link>https://kevinkwl.github.io/tags/nlp/</link>
    <description>Recent content in Nlp on Kangwei Ling</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 May 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://kevinkwl.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Learning Topic-Sensitive Word Representations</title>
      <link>https://kevinkwl.github.io/writing/learn-topic-sensitive-word-representations/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://kevinkwl.github.io/writing/learn-topic-sensitive-word-representations/</guid>
      <description>Link to paper
About Word Embedding The concept (or technique) of Word Embedding plays a crucial role in the recent Natural Language Processing field. Instead of high-dimensional (vocabulary size), extremely sparse (one-hot) vectors, smaller size (Most existing word embedding models (word2vec, glove, ...) only use one representation per word. Though these models have already achieved amazing results on many task, they fail to distinguish different meanings of polysemous words. For example, the word bank, has two distinct meanings which can only be inferred from the context.</description>
    </item>
    
  </channel>
</rss>